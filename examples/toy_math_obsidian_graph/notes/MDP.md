---
tags:
  - RL
  - SYS/DEPRECATED
---
MDP - [[Марковское свойство|Марковский]] Процесс Принятия Решений, [[RL парадигма]] рассматривает таким образом задачи эпизодического сеттинга.
![[MDP.png]]
$MDP = \{\mathcal{S}, \mathcal{A}(s), \mathcal{R}(s|a)\}$, подразумевает наличие модели награды и перехода, динамическая модель образованная $\{\mathcal{P},\mathcal{R}\}$ при этом такова, что вероятности (стационарные или динамические) обладают марковскими свойствами:
$$\bigg[p(s_{t+1}|s_t,a_t, ... s_0, a_0) = p(s_{t+1}|s_t, a_t)\bigg] \cap \bigg[p(r_{t+1}|s_t,a_t, ... s_0, a_0) = p(r_{t+1}|s_t, a_t)\bigg]$$
MDP рассматривается как фреймворк динамической стохастической модели, при фиксации политики $\pi$ как одной конкретной обращается в стандартный [[MP|марковский процесс]].