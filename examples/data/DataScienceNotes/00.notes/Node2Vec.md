---
tags:
  - Graphs
  - GraphML
layer: bronze
---
![[n2v_edge_types.png]]
В  N2V рассматривается более сложный вариант семплирования вершин в графе. DFS и BFS обходы сформируют контексты из вершин, обучение на которых приведет к склонности эмбеддингов соответственно к выполнению [[Гипотеза структурной эквивалентности в графах|гипотезы структурной эквивалентности]]  и [[Гомофильная гипотеза в графах|гомофильной гипотезы]]. Стратегия семплирования названная biased random walk задается следующим образом:
Для создания компромисса (DFS и BFS - это экстремальные случаи, первый построит пути максимально отдаляющиеся от старта, второй пройдет всю окрестность и только далее по возрастанию расстояния) при выборе следующей вершины параметризуются вероятность перехода в окрестной следующей вершины и вероятность остаться в окрестности прошлой вершины.

Рассматриваются три случая, зависящие от прошлого перехода между вершинами (метод обхода второго порядка):
$$
\alpha_{v,x} = \alpha_{p,q}(t,x) = \begin{cases} 
\frac{1}{p}, x \in \mathcal{N}(t) \\ 
1\text{ }, x = t\\ 
\frac{1}{q}, x \notin \mathcal{N}(t) \\
\end{cases}
$$
Далее требуется нормализовать значения для получения вероятности:
$$\hat{\mathbb{p}}(v \rightarrow x_i) = \hat{\alpha}_{v,x_i} = \frac{\alpha_p^q(t,x_i)}{\sum_{x_j \in \mathcal{N}(v)}\alpha_p^q(t,x_j)}$$
Для взвешенных графов с $\mathbb{W}\in\mathbb{R}^{|\mathbb{V}|\times|\mathbb{V}|}:\hat{\mathbb{p}}(v \rightarrow x_i) = \hat{\alpha}_{v,x_i}*w_{v,x_i}$

Варьирование параметров *p* и *q* позволяет гибко задавать поведение алгоритма и свойство выученных представлений, что позволяет найти оптимум для задач.

После сэмплирования методика обучения аналогична [[DeepWalk]].